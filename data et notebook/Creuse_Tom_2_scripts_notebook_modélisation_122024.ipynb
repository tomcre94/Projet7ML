{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement et exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T15:49:00.732501Z",
     "start_time": "2025-01-25T15:48:27.598781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage de 20 lignes aléatoires :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73358</th>\n",
       "      <td>0</td>\n",
       "      <td>1694487089</td>\n",
       "      <td>Mon May 04 02:51:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>allyeezy</td>\n",
       "      <td>tssss! im feelin like im about to let go.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081455</th>\n",
       "      <td>4</td>\n",
       "      <td>1968464398</td>\n",
       "      <td>Fri May 29 21:29:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>FadingLullabies</td>\n",
       "      <td>@nevershoutnneka haha well thats good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170101</th>\n",
       "      <td>4</td>\n",
       "      <td>1980331756</td>\n",
       "      <td>Sun May 31 06:25:48 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cdgriffi</td>\n",
       "      <td>@abednego_jones I'm STILL laughing at ur fooli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192698</th>\n",
       "      <td>0</td>\n",
       "      <td>1969903053</td>\n",
       "      <td>Sat May 30 01:40:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>siobhanyy</td>\n",
       "      <td>i miss the suspense of waiting for the harry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221685</th>\n",
       "      <td>0</td>\n",
       "      <td>1976875249</td>\n",
       "      <td>Sat May 30 19:23:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>houshuang</td>\n",
       "      <td>When I was studying Chinese in Sweden, they ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105273</th>\n",
       "      <td>0</td>\n",
       "      <td>1822935168</td>\n",
       "      <td>Sat May 16 20:43:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Galley99</td>\n",
       "      <td>MADtv is gone. RIP, and thanks for all the lau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515500</th>\n",
       "      <td>4</td>\n",
       "      <td>2175608742</td>\n",
       "      <td>Mon Jun 15 01:28:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ggw_bach</td>\n",
       "      <td>@osanewsletter everything has a twinkling frac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223805</th>\n",
       "      <td>0</td>\n",
       "      <td>1977274201</td>\n",
       "      <td>Sat May 30 20:33:32 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Diamondz95</td>\n",
       "      <td>Too bad Cavs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383039</th>\n",
       "      <td>4</td>\n",
       "      <td>2052524051</td>\n",
       "      <td>Sat Jun 06 01:01:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>heymiks</td>\n",
       "      <td>@annevdns haha yup, that was around 1981 i thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834537</th>\n",
       "      <td>4</td>\n",
       "      <td>1557981462</td>\n",
       "      <td>Sun Apr 19 06:49:23 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Lavetta</td>\n",
       "      <td>@sillycows thanks for the follow friday mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369231</th>\n",
       "      <td>0</td>\n",
       "      <td>2049781613</td>\n",
       "      <td>Fri Jun 05 17:29:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>christiecoo</td>\n",
       "      <td>Aw the video's not working  oh well, I'm watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097996</th>\n",
       "      <td>4</td>\n",
       "      <td>1970444267</td>\n",
       "      <td>Sat May 30 03:53:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kowusu</td>\n",
       "      <td>just finished with the session!! Ahh Music!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675542</th>\n",
       "      <td>0</td>\n",
       "      <td>2248119830</td>\n",
       "      <td>Fri Jun 19 20:07:54 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kylmock</td>\n",
       "      <td>wow so a couple of tweet via txt went ape shit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177464</th>\n",
       "      <td>0</td>\n",
       "      <td>1965665033</td>\n",
       "      <td>Fri May 29 16:19:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>LaBellaBeauty</td>\n",
       "      <td>Is it wrong that I love John Travolta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191813</th>\n",
       "      <td>0</td>\n",
       "      <td>1969714965</td>\n",
       "      <td>Sat May 30 00:58:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jakeishottie</td>\n",
       "      <td>30 day ban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538475</th>\n",
       "      <td>4</td>\n",
       "      <td>2179877026</td>\n",
       "      <td>Mon Jun 15 09:42:21 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>zefrog</td>\n",
       "      <td>@Clydebuilt you sound like one in that clip too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157594</th>\n",
       "      <td>4</td>\n",
       "      <td>1979192177</td>\n",
       "      <td>Sun May 31 02:00:25 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>spotonpr</td>\n",
       "      <td>@dxbluey That's technology! Always costs more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29473</th>\n",
       "      <td>0</td>\n",
       "      <td>1563487038</td>\n",
       "      <td>Sun Apr 19 23:01:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>comeonnowsugar</td>\n",
       "      <td>I have a headache. ANd I have to pee. And my l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669882</th>\n",
       "      <td>0</td>\n",
       "      <td>2246387633</td>\n",
       "      <td>Fri Jun 19 17:31:15 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Christyxcore</td>\n",
       "      <td>@Jasperblu Oh. Sorry, I didn't know.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353110</th>\n",
       "      <td>4</td>\n",
       "      <td>2046638696</td>\n",
       "      <td>Fri Jun 05 12:28:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x0me880x</td>\n",
       "      <td>@Fionaw77 I can't believe something so fun, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target         ids                          date      flag  \\\n",
       "73358        0  1694487089  Mon May 04 02:51:03 PDT 2009  NO_QUERY   \n",
       "1081455      4  1968464398  Fri May 29 21:29:36 PDT 2009  NO_QUERY   \n",
       "1170101      4  1980331756  Sun May 31 06:25:48 PDT 2009  NO_QUERY   \n",
       "192698       0  1969903053  Sat May 30 01:40:05 PDT 2009  NO_QUERY   \n",
       "221685       0  1976875249  Sat May 30 19:23:38 PDT 2009  NO_QUERY   \n",
       "105273       0  1822935168  Sat May 16 20:43:44 PDT 2009  NO_QUERY   \n",
       "1515500      4  2175608742  Mon Jun 15 01:28:29 PDT 2009  NO_QUERY   \n",
       "223805       0  1977274201  Sat May 30 20:33:32 PDT 2009  NO_QUERY   \n",
       "1383039      4  2052524051  Sat Jun 06 01:01:38 PDT 2009  NO_QUERY   \n",
       "834537       4  1557981462  Sun Apr 19 06:49:23 PDT 2009  NO_QUERY   \n",
       "369231       0  2049781613  Fri Jun 05 17:29:24 PDT 2009  NO_QUERY   \n",
       "1097996      4  1970444267  Sat May 30 03:53:38 PDT 2009  NO_QUERY   \n",
       "675542       0  2248119830  Fri Jun 19 20:07:54 PDT 2009  NO_QUERY   \n",
       "177464       0  1965665033  Fri May 29 16:19:20 PDT 2009  NO_QUERY   \n",
       "191813       0  1969714965  Sat May 30 00:58:06 PDT 2009  NO_QUERY   \n",
       "1538475      4  2179877026  Mon Jun 15 09:42:21 PDT 2009  NO_QUERY   \n",
       "1157594      4  1979192177  Sun May 31 02:00:25 PDT 2009  NO_QUERY   \n",
       "29473        0  1563487038  Sun Apr 19 23:01:27 PDT 2009  NO_QUERY   \n",
       "669882       0  2246387633  Fri Jun 19 17:31:15 PDT 2009  NO_QUERY   \n",
       "1353110      4  2046638696  Fri Jun 05 12:28:33 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "73358           allyeezy         tssss! im feelin like im about to let go.   \n",
       "1081455  FadingLullabies             @nevershoutnneka haha well thats good   \n",
       "1170101         cdgriffi  @abednego_jones I'm STILL laughing at ur fooli...  \n",
       "192698         siobhanyy   i miss the suspense of waiting for the harry ...  \n",
       "221685         houshuang  When I was studying Chinese in Sweden, they ne...  \n",
       "105273          Galley99  MADtv is gone. RIP, and thanks for all the lau...  \n",
       "1515500         ggw_bach  @osanewsletter everything has a twinkling frac...  \n",
       "223805        Diamondz95                                      Too bad Cavs   \n",
       "1383039          heymiks  @annevdns haha yup, that was around 1981 i thi...  \n",
       "834537           Lavetta   @sillycows thanks for the follow friday mention   \n",
       "369231       christiecoo  Aw the video's not working  oh well, I'm watch...  \n",
       "1097996           kowusu       just finished with the session!! Ahh Music!   \n",
       "675542           kylmock  wow so a couple of tweet via txt went ape shit...  \n",
       "177464     LaBellaBeauty             Is it wrong that I love John Travolta   \n",
       "191813      jakeishottie                                        30 day ban   \n",
       "1538475           zefrog   @Clydebuilt you sound like one in that clip too   \n",
       "1157594         spotonpr  @dxbluey That's technology! Always costs more ...  \n",
       "29473     comeonnowsugar  I have a headache. ANd I have to pee. And my l...  \n",
       "669882      Christyxcore              @Jasperblu Oh. Sorry, I didn't know.   \n",
       "1353110         x0me880x  @Fionaw77 I can't believe something so fun, th...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiques descriptives :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600018</td>\n",
       "      <td>1600018</td>\n",
       "      <td>1600018</td>\n",
       "      <td>1600018</td>\n",
       "      <td>1600018</td>\n",
       "      <td>1600018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>1598316</td>\n",
       "      <td>774364</td>\n",
       "      <td>2</td>\n",
       "      <td>659776</td>\n",
       "      <td>1581467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>positif</td>\n",
       "      <td>ids</td>\n",
       "      <td>Mon Jun 15 12:53:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lost_dog</td>\n",
       "      <td>isPlayer Has Died! Sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>800000</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>1600000</td>\n",
       "      <td>549</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target      ids                          date      flag      user  \\\n",
       "count   1600018  1600018                       1600018   1600018   1600018   \n",
       "unique        3  1598316                        774364         2    659776   \n",
       "top     positif      ids  Mon Jun 15 12:53:14 PDT 2009  NO_QUERY  lost_dog   \n",
       "freq     800000       18                            20   1600000       549   \n",
       "\n",
       "                             text  \n",
       "count                     1600018  \n",
       "unique                    1581467  \n",
       "top     isPlayer Has Died! Sorry   \n",
       "freq                          210  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs manquantes par colonne :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "ids       0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chemin du fichier\n",
    "file_path = 'Dataset_Init.csv'\n",
    "\n",
    "# Les titres que vous souhaitez ajouter\n",
    "headers = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "\n",
    "# Lire les données existantes\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "# Écrire les titres et ajouter les anciennes données\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    # Ajouter les titres\n",
    "    file.write(\",\".join(headers) + \"\\n\")\n",
    "    # Ajouter les anciennes données\n",
    "    file.writelines(data)\n",
    "\n",
    "# Spécifiez les types de données pour les colonnes 0 et 1\n",
    "dtype_spec = {\n",
    "    \"target\": 'str',\n",
    "    \"ids\": 'str'\n",
    "}\n",
    "\n",
    "# Lire le fichier CSV avec les types de données spécifiés\n",
    "df = pd.read_csv(file_path, dtype=dtype_spec, low_memory=False)\n",
    "\n",
    "# Sélectionner 20 lignes aléatoires\n",
    "random_rows = df.sample(n=20)\n",
    "\n",
    "# Afficher les lignes sélectionnées\n",
    "print(\"Affichage de 20 lignes aléatoires :\")\n",
    "display(random_rows)\n",
    "\n",
    "# Regroupement des valeurs de la colonne 'target' en catégories\n",
    "df['target'] = df['target'].apply(lambda x: 'positif' if x == '4' else 'négatif' if x == '0' else 'neutre')\n",
    "\n",
    "# Assurez-vous que toutes les catégories sont présentes\n",
    "df['target'] = pd.Categorical(df['target'], categories=['positif', 'négatif', 'neutre'])\n",
    "\n",
    "# Compter les occurrences de chaque valeur dans la colonne 'target'\n",
    "target_counts = df['target'].value_counts()\n",
    "\n",
    "# Créer un graphique à barres\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = target_counts.plot(kind='bar')\n",
    "plt.title('Répartition des valeurs de la variable target')\n",
    "plt.xlabel('Valeurs de target')\n",
    "plt.ylabel('Nombre d\\'occurrences')\n",
    "\n",
    "# Modifier les noms des colonnes en abscisse\n",
    "ax.set_xticklabels(['positif', 'négatif', 'neutre'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Afficher les statistiques descriptives\n",
    "print(\"Statistiques descriptives :\")\n",
    "display(df.describe(include='all'))\n",
    "\n",
    "# Afficher les valeurs manquantes\n",
    "print(\"Valeurs manquantes par colonne :\")\n",
    "display(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T15:55:31.786697Z",
     "start_time": "2025-01-25T15:55:13.720175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234187</th>\n",
       "      <td>0</td>\n",
       "      <td>1979529677</td>\n",
       "      <td>Sun May 31 03:26:34 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>archnix</td>\n",
       "      <td>bad weather  !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794126</th>\n",
       "      <td>0</td>\n",
       "      <td>2326866322</td>\n",
       "      <td>Thu Jun 25 07:36:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jill777</td>\n",
       "      <td>@DonnieWahlberg Morning! Will you @jasonjmikem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605910</th>\n",
       "      <td>0</td>\n",
       "      <td>2222409635</td>\n",
       "      <td>Thu Jun 18 06:56:40 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>jdillon05</td>\n",
       "      <td>Headed to the Beach for my last full day on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>0</td>\n",
       "      <td>1557961813</td>\n",
       "      <td>Sun Apr 19 06:44:42 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>theGreener</td>\n",
       "      <td>Lost to the scum, depressed now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294816</th>\n",
       "      <td>0</td>\n",
       "      <td>1996693840</td>\n",
       "      <td>Mon Jun 01 15:31:26 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>arythmaticflow</td>\n",
       "      <td>@starlaboob Well that sucks.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target         ids                          date      flag  \\\n",
       "234187      0  1979529677  Sun May 31 03:26:34 PDT 2009  NO_QUERY   \n",
       "794126      0  2326866322  Thu Jun 25 07:36:53 PDT 2009  NO_QUERY   \n",
       "605910      0  2222409635  Thu Jun 18 06:56:40 PDT 2009  NO_QUERY   \n",
       "24337       0  1557961813  Sun Apr 19 06:44:42 PDT 2009  NO_QUERY   \n",
       "294816      0  1996693840  Mon Jun 01 15:31:26 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  user                                               text  \n",
       "234187         archnix                                    bad weather  !!  \n",
       "794126         jill777  @DonnieWahlberg Morning! Will you @jasonjmikem...  \n",
       "605910       jdillon05  Headed to the Beach for my last full day on th...  \n",
       "24337       theGreener                   Lost to the scum, depressed now   \n",
       "294816  arythmaticflow                      @starlaboob Well that sucks.   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spécifier les types de données des colonnes\n",
    "dtype_spec = {\n",
    "    \"target\": 'str',\n",
    "    \"ids\": 'str'\n",
    "}\n",
    "\n",
    "# Charger le fichier CSV dans un DataFrame avec les types de données spécifiés\n",
    "df = pd.read_csv('Dataset_Init.csv', dtype=dtype_spec, low_memory=False)\n",
    "\n",
    "# Convertir la colonne 'target' en type string\n",
    "df['target'] = df['target'].astype(str)\n",
    "\n",
    "# Diviser le DataFrame en 132 000 lignes tout en maintenant l'équilibre de la colonne 'target'\n",
    "df_sampled, _ = train_test_split(df, train_size=132000, stratify=df['target'], random_state=42)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame échantillonné\n",
    "display(df_sampled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement, Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T16:34:27.624653Z",
     "start_time": "2025-01-25T16:22:22.465102Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\creus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\creus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\creus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\creus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prétraitement des tweets...\n",
      "\n",
      "Création des embeddings Word2Vec...\n",
      "\n",
      "Création des embeddings FastText...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Configuration initiale\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialisation des outils\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words -= {'no', 'not', 'nor', 'none', 'never', 'nothing', 'nowhere', 'hardly', 'barely', 'scarcely'}\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\n",
    "        \"J\": wordnet.ADJ,\n",
    "        \"N\": wordnet.NOUN,\n",
    "        \"V\": wordnet.VERB,\n",
    "        \"R\": wordnet.ADV\n",
    "    }\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Prétraitement unifié pour tous les modèles\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "        \n",
    "    # Conversion des emojis en texte\n",
    "    text = emoji.demojize(text)\n",
    "    \n",
    "    # Expansion des contractions\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Nettoyage des URLs, mentions et hashtags\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', 'URL', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\@\\w+', 'mention', text)\n",
    "    text = re.sub(r'\\#(\\w+)', r'\\1', text)\n",
    "    \n",
    "    # Gestion des répétitions de lettres\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "    \n",
    "    # Tokenisation\n",
    "    tokens = tweet_tokenizer.tokenize(text)\n",
    "    \n",
    "    # Nettoyage et normalisation\n",
    "    tokens = [token for token in tokens if (\n",
    "        token not in stop_words and\n",
    "        len(token) > 1 and\n",
    "        not token.isnumeric()\n",
    "    )]\n",
    "    \n",
    "    # Lemmatisation avec POS tagging\n",
    "    tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) \n",
    "             for token in tokens]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Prétraitement du DataFrame\n",
    "print(\"Prétraitement des tweets...\")\n",
    "df_sampled['cleaned_text'] = df_sampled['text'].apply(clean_text)\n",
    "df_sampled['cleaned_text_str'] = df_sampled['cleaned_text'].apply(' '.join)\n",
    "\n",
    "# Word2Vec\n",
    "print(\"\\nCréation des embeddings Word2Vec...\")\n",
    "from gensim.models import Word2Vec\n",
    "model_w2v = Word2Vec(sentences=df_sampled['cleaned_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "df_sampled['w2v'] = df_sampled['cleaned_text'].apply(\n",
    "    lambda x: model_w2v.wv[x].mean(axis=0) if len(x) > 0 else np.zeros(100)\n",
    ")\n",
    "\n",
    "# FastText\n",
    "print(\"\\nCréation des embeddings FastText...\")\n",
    "from gensim.models import FastText\n",
    "model_fasttext = FastText(sentences=df_sampled['cleaned_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "df_sampled['fasttext'] = df_sampled['cleaned_text'].apply(\n",
    "    lambda x: model_fasttext.wv[x].mean(axis=0) if len(x) > 0 else np.zeros(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création des embeddings BERT...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCréation des embeddings BERT...\")\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    outputs = model_bert(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\n",
    "# Initialiser une liste pour stocker les embeddings\n",
    "bert_embeddings = []\n",
    "\n",
    "# Utiliser une boucle for pour itérer sur les textes\n",
    "for text in df_sampled['cleaned_text_str']:\n",
    "    embedding = get_bert_embeddings(text).flatten()\n",
    "    bert_embeddings.append(embedding)\n",
    "\n",
    "# Ajouter les embeddings au DataFrame\n",
    "df_sampled['bert'] = bert_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-25T19:26:09.584863Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création des embeddings USE...\n",
      "WARNING:tensorflow:From c:\\Users\\creus\\OneDrive\\Bureau\\IA\\Projet 7\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\creus\\OneDrive\\Bureau\\IA\\Projet 7\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCréation des embeddings USE...\")\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model_use = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\")\n",
    "\n",
    "def get_use_embeddings(text):\n",
    "    return model_use([text]).numpy()[0]\n",
    "\n",
    "# Initialiser une liste pour stocker les embeddings\n",
    "use_embeddings = []\n",
    "\n",
    "# Utiliser une boucle for pour itérer sur les textes\n",
    "for text in df_sampled['cleaned_text_str']:\n",
    "    embedding = get_use_embeddings(text)\n",
    "    use_embeddings.append(embedding)\n",
    "\n",
    "# Ajouter les embeddings au DataFrame\n",
    "df_sampled['use'] = use_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T15:41:23.045938Z",
     "start_time": "2025-01-12T15:40:03.108600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Création des embeddings GloVe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creus\\AppData\\Local\\Temp\\ipykernel_13256\\2350692942.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCréation des embeddings GloVe...\")\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "glove_input_file = '../glove.6B.100d.txt'\n",
    "word2vec_output_file = '../glove.6B.100d.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "model_glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "\n",
    "# Construire un dictionnaire des vecteurs pour les mots utilisés\n",
    "vocab = set(word for tokens in df_sampled['cleaned_text'] for word in tokens)\n",
    "word_vectors = {word: model_glove[word] for word in vocab if word in model_glove}\n",
    "\n",
    "def get_glove_embeddings(tokens):\n",
    "    vectors = [word_vectors[word] for word in tokens if word in word_vectors]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
    "\n",
    "# Initialiser une liste pour stocker les embeddings\n",
    "glove_embeddings = []\n",
    "\n",
    "# Utiliser une boucle for pour itérer sur les textes\n",
    "for tokens in df_sampled['cleaned_text']:\n",
    "    embedding = get_glove_embeddings(tokens)\n",
    "    glove_embeddings.append(embedding)\n",
    "\n",
    "# Ajouter les embeddings au DataFrame\n",
    "df_sampled['glove'] = glove_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques des embeddings :\n",
      "Dimension Word2Vec : (100,)\n",
      "Dimension FastText : (100,)\n",
      "Dimension BERT : (768,)\n",
      "Dimension USE : (512,)\n",
      "Dimension GloVe : (100,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStatistiques des embeddings :\")\n",
    "print(f\"Dimension Word2Vec : {df_sampled['w2v'].iloc[0].shape}\")\n",
    "print(f\"Dimension FastText : {df_sampled['fasttext'].iloc[0].shape}\")\n",
    "print(f\"Dimension BERT : {df_sampled['bert'].iloc[0].shape}\")\n",
    "print(f\"Dimension USE : {df_sampled['use'].iloc[0].shape}\")\n",
    "print(f\"Dimension GloVe : {df_sampled['glove'].iloc[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Évaluation des performances via ARI et t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T15:58:39.035695Z",
     "start_time": "2025-01-12T15:41:33.106373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI Word2Vec: 0.019832332914912425\n",
      "ARI BERT: 0.001979563432992251\n",
      "ARI USE: 0.014538971106932965\n",
      "ARI GloVe: 0.01639511822337138\n",
      "ARI FastText: 0.012297437952628078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Utilisation de la variable target comme étiquettes\n",
    "true_labels = df_sampled['target'].astype('category').cat.codes\n",
    "\n",
    "# Convertir les colonnes d'embeddings en numpy arrays\n",
    "w2v_embeddings = np.vstack(df_sampled['w2v'].values)\n",
    "bert_embeddings = np.vstack(df_sampled['bert'].values)\n",
    "use_embeddings = np.vstack(df_sampled['use'].values)\n",
    "glove_embeddings = np.vstack(df_sampled['glove'].values)\n",
    "fasttext_embeddings = np.vstack(df_sampled['fasttext'].values)\n",
    "\n",
    "# Normaliser les embeddings\n",
    "scaler = StandardScaler()\n",
    "w2v_embeddings_scaled = scaler.fit_transform(w2v_embeddings)\n",
    "bert_embeddings_scaled = scaler.fit_transform(bert_embeddings)\n",
    "use_embeddings_scaled = scaler.fit_transform(use_embeddings)\n",
    "glove_embeddings_scaled = scaler.fit_transform(glove_embeddings)\n",
    "fasttext_embeddings_scaled = scaler.fit_transform(fasttext_embeddings)\n",
    "\n",
    "# Clustering avec KMeans sur les embeddings normalisés\n",
    "n_clusters = len([label for label in np.unique(true_labels) if np.sum(true_labels == label) > 0])\n",
    "kmeans_w2v = KMeans(n_clusters=n_clusters, random_state=42).fit(w2v_embeddings_scaled)\n",
    "kmeans_bert = KMeans(n_clusters=n_clusters, random_state=42).fit(bert_embeddings_scaled)\n",
    "kmeans_use = KMeans(n_clusters=n_clusters, random_state=42).fit(use_embeddings_scaled)\n",
    "kmeans_glove = KMeans(n_clusters=n_clusters, random_state=42).fit(glove_embeddings_scaled)\n",
    "kmeans_fasttext = KMeans(n_clusters=n_clusters, random_state=42).fit(fasttext_embeddings_scaled)\n",
    "\n",
    "# Exemple d'évaluation avec ARI\n",
    "ari_w2v = adjusted_rand_score(true_labels, kmeans_w2v.labels_)\n",
    "ari_bert = adjusted_rand_score(true_labels, kmeans_bert.labels_)\n",
    "ari_use = adjusted_rand_score(true_labels, kmeans_use.labels_)\n",
    "ari_glove = adjusted_rand_score(true_labels, kmeans_glove.labels_)\n",
    "ari_fasttext = adjusted_rand_score(true_labels, kmeans_fasttext.labels_)\n",
    "\n",
    "print(f\"ARI Word2Vec: {ari_w2v}\")\n",
    "print(f\"ARI BERT: {ari_bert}\")\n",
    "print(f\"ARI USE: {ari_use}\")\n",
    "print(f\"ARI GloVe: {ari_glove}\")\n",
    "print(f\"ARI FastText: {ari_fasttext}\")\n",
    "\n",
    "# Visualisation avec t-SNE\n",
    "def plot_tsne(embeddings, labels, title):\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Exemple de visualisation\n",
    "plot_tsne(w2v_embeddings, true_labels, 't-SNE Word2Vec')\n",
    "plot_tsne(bert_embeddings, true_labels, 't-SNE BERT')\n",
    "plot_tsne(use_embeddings, true_labels, 't-SNE USE')\n",
    "plot_tsne(glove_embeddings, true_labels, 't-SNE GloVe')\n",
    "plot_tsne(fasttext_embeddings, true_labels, 't-SNE FastText')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests de 3 modèles via MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation des embeddings USE de df_sampled\n",
    "X = np.vstack(df_sampled['use'].values)\n",
    "y = df_sampled['target'].values\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLFlow\n",
    "mlflow.set_experiment(\"Experimentation_projet_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "import mlflow\n",
    "\n",
    "# Convertir d'abord les étiquettes en numérique si elles sont en string\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "# Convertir les étiquettes 4 en 1\n",
    "y_train = np.where(y_train == 4, 1, 0)  # Convertit explicitement en binaire 0/1\n",
    "y_test = np.where(y_test == 4, 1, 0)    # Convertit explicitement en binaire 0/1\n",
    "\n",
    "# Modèle de Régression Logistique\n",
    "with mlflow.start_run(run_name=\"Logistic_Regression_USE\"):\n",
    "    model_lr = LogisticRegression(random_state=42)\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions sur l'ensemble d'entraînement\n",
    "    y_pred_lr = model_lr.predict(X_train)\n",
    "    y_pred_proba_lr = model_lr.predict_proba(X_train)[:, 1]  # Probabilités pour la classe positive\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    f1_lr = f1_score(y_train, y_pred_lr)\n",
    "    precision_lr = precision_score(y_train, y_pred_lr)\n",
    "    recall_lr = recall_score(y_train, y_pred_lr)\n",
    "    auc_lr = roc_auc_score(y_train, y_pred_proba_lr)\n",
    "    \n",
    "    # Logging des métriques dans MLflow\n",
    "    mlflow.log_metric(\"f1_score\", f1_lr)\n",
    "    mlflow.log_metric(\"precision\", precision_lr)\n",
    "    mlflow.log_metric(\"recall\", recall_lr)\n",
    "    mlflow.log_metric(\"auc\", auc_lr)\n",
    "    \n",
    "    # Sauvegarde du modèle\n",
    "    mlflow.sklearn.log_model(model_lr, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "import mlflow\n",
    "\n",
    "# Conversion des étiquettes en format binaire 0/1\n",
    "y_train_lstm = np.where(y_train == 4, 1, 0)\n",
    "y_test_lstm = np.where(y_test == 4, 1, 0)\n",
    "\n",
    "# LSTM Model\n",
    "with mlflow.start_run(run_name=\"LSTM\"):\n",
    "    # Définition du modèle\n",
    "    model_lstm = Sequential([\n",
    "        Embedding(5000, 100, weights=[embedding_matrix], input_length=100, trainable=False),\n",
    "        SpatialDropout1D(0.2),\n",
    "        LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compilation du modèle\n",
    "    model_lstm.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callback pour early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    history = model_lstm.fit(\n",
    "        X_train,\n",
    "        y_train_lstm,\n",
    "        epochs=10,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred_proba = model_lstm.predict(X_test)\n",
    "    y_pred_lstm = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    f1_lstm = f1_score(y_test_lstm, y_pred_lstm)\n",
    "    precision_lstm = precision_score(y_test_lstm, y_pred_lstm)\n",
    "    recall_lstm = recall_score(y_test_lstm, y_pred_lstm)\n",
    "    auc_lstm = roc_auc_score(y_test_lstm, y_pred_proba)\n",
    "    \n",
    "    # Logging des paramètres\n",
    "    mlflow.log_param(\"num_words\", 5000)\n",
    "    mlflow.log_param(\"embedding_dim\", 100)\n",
    "    mlflow.log_param(\"maxlen\", 100)\n",
    "    mlflow.log_param(\"lstm_units\", 100)\n",
    "    mlflow.log_param(\"dropout_rate\", 0.2)\n",
    "    \n",
    "    # Logging des métriques\n",
    "    mlflow.log_metric(\"f1_score\", f1_lstm)\n",
    "    mlflow.log_metric(\"precision\", precision_lstm)\n",
    "    mlflow.log_metric(\"recall\", recall_lstm)\n",
    "    mlflow.log_metric(\"auc\", auc_lstm)\n",
    "    \n",
    "    # Logging des métriques d'entraînement\n",
    "    for epoch, (loss, val_loss) in enumerate(zip(history.history['loss'], history.history['val_loss'])):\n",
    "        mlflow.log_metric(f\"train_loss_epoch_{epoch+1}\", loss)\n",
    "        mlflow.log_metric(f\"val_loss_epoch_{epoch+1}\", val_loss)\n",
    "    \n",
    "    # Sauvegarde du modèle au format HDF5\n",
    "    model_lstm.save(\"model_lstm.h5\")\n",
    "    mlflow.log_artifact(\"model_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define the model architecture\n",
    "new_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(512,), name='input_layer_2'),\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=5000,  # Vocabulary size\n",
    "        output_dim=100,  # Embedding dimension\n",
    "        name='embedding_3'\n",
    "    ),\n",
    "    tf.keras.layers.SpatialDropout1D(0.3, name='spatial_dropout1d_3'),\n",
    "    tf.keras.layers.LSTM(100, name='lstm_3'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid', name='dense_7')\n",
    "])\n",
    "\n",
    "# Load the original model\n",
    "original_model = tf.keras.models.load_model('model_lstm.h5')\n",
    "\n",
    "# Copy the weights from the original model to the new model\n",
    "for i in range(len(original_model.layers)):\n",
    "    try:\n",
    "        new_model.layers[i].set_weights(original_model.layers[i].get_weights())\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying weights for layer {i}: {str(e)}\")\n",
    "\n",
    "# Compile the model\n",
    "new_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Save the new model in the recommended Keras format\n",
    "new_model.save(\"model_lstm_compatible.h5\")\n",
    "\n",
    "# Verify that the model has been saved correctly\n",
    "test_model = tf.keras.models.load_model('model_lstm_compatible.keras')\n",
    "print(\"New model created and saved successfully!\")\n",
    "\n",
    "# Display the summary of the new model for verification\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Charger votre modèle\n",
    "model = tf.keras.models.load_model('model_lstm.h5')\n",
    "\n",
    "# Afficher la structure du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Désactiver la journalisation automatique de mlflow.tensorflow\n",
    "mlflow.tensorflow.autolog(disable=True)\n",
    "\n",
    "# Conversion des étiquettes en format binaire 0/1\n",
    "y_train_bert = np.where(y_train == 4, 1, 0)\n",
    "y_test_bert = np.where(y_test == 4, 1, 0)\n",
    "\n",
    "# Démarrer une session MLflow\n",
    "with mlflow.start_run(run_name=\"BERT_approach_fast\"):\n",
    "    # Charger le tokenizer et le modèle de base BERT\n",
    "    tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Convertir les données en liste de strings si ce n'est pas déjà le cas\n",
    "    if isinstance(X_train[0], str):\n",
    "        X_train_texts = X_train[:1000]  # Limiter à 1000 échantillons pour l'entraînement\n",
    "        X_test_texts = X_test[:200]     # Limiter à 200 échantillons pour le test\n",
    "    else:\n",
    "        X_train_texts = [str(text) for text in X_train[:1000]]\n",
    "        X_test_texts = [str(text) for text in X_test[:200]]\n",
    "    \n",
    "    # Ajuster les labels en conséquence\n",
    "    y_train_bert = y_train_bert[:1000]\n",
    "    y_test_bert = y_test_bert[:200]\n",
    "    \n",
    "    # Tokenizer avec une longueur maximale réduite\n",
    "    train_encodings = tokenizer_bert(\n",
    "        X_train_texts, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=128,  # Réduit de 512 à 128\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    test_encodings = tokenizer_bert(\n",
    "        X_test_texts, \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=128,  # Réduit de 512 à 128\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "    # Augmenter la taille du batch pour plus de rapidité\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(train_encodings),\n",
    "        y_train_bert\n",
    "    )).batch(32)  # Augmenté de 16 à 32\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        dict(test_encodings),\n",
    "        y_test_bert\n",
    "    )).batch(32)  # Augmenté de 16 à 32\n",
    "\n",
    "    class BertClassifier(tf.keras.Model):\n",
    "        def __init__(self, bert_model):\n",
    "            super().__init__()\n",
    "            self.bert = bert_model\n",
    "            self.dropout = tf.keras.layers.Dropout(0.1)\n",
    "            self.classifier = Dense(1, activation='sigmoid')\n",
    "            \n",
    "        def call(self, inputs, training=False):\n",
    "            input_ids = tf.cast(inputs['input_ids'], tf.int32)\n",
    "            attention_mask = tf.cast(inputs['attention_mask'], tf.int32)\n",
    "            \n",
    "            outputs = self.bert(\n",
    "                input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                training=False\n",
    "            )\n",
    "            \n",
    "            pooled_output = outputs[1]\n",
    "            pooled_output = self.dropout(pooled_output, training=training)\n",
    "            return self.classifier(pooled_output)\n",
    "\n",
    "    base_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    model_bert = BertClassifier(base_model)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)  # Légèrement augmenté\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    metrics = [tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")]  # Réduit le nombre de métriques\n",
    "\n",
    "    model_bert.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=1,  # Réduit de 2 à 1\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model_bert.fit(\n",
    "        train_dataset,\n",
    "        epochs=2,  # Réduit de 3 à 2\n",
    "        validation_data=test_dataset,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    y_pred_proba = model_bert.predict(test_dataset, batch_size=32).ravel()\n",
    "    y_pred_bert = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Calculer les métriques finales\n",
    "    f1_bert = f1_score(y_test_bert, y_pred_bert)\n",
    "    precision_bert = precision_score(y_test_bert, y_pred_bert)\n",
    "    recall_bert = recall_score(y_test_bert, y_pred_bert)\n",
    "    auc_bert = roc_auc_score(y_test_bert, y_pred_proba)\n",
    "\n",
    "    # Logger les métriques et paramètres\n",
    "    mlflow.log_param(\"model_type\", \"BERT_fast\")\n",
    "    mlflow.log_param(\"max_length\", 128)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"epochs\", 2)\n",
    "    mlflow.log_param(\"training_samples\", 1000)\n",
    "    mlflow.log_param(\"test_samples\", 200)\n",
    "\n",
    "    mlflow.log_metric(\"f1_score\", f1_bert)\n",
    "    mlflow.log_metric(\"precision\", precision_bert)\n",
    "    mlflow.log_metric(\"recall\", recall_bert)\n",
    "    mlflow.log_metric(\"auc\", auc_bert)\n",
    "\n",
    "    weights_path = \"bert_model_weights.weights.h5\"\n",
    "    model_bert.save_weights(weights_path)\n",
    "    if os.path.exists(weights_path):\n",
    "        mlflow.log_artifact(weights_path)\n",
    "        os.remove(weights_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
